{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Briefer\n",
    "\n",
    "### Building News Briefer Using GloVe Algorithm\n",
    "\n",
    "This notebook is for building a news briefer/summarizer. We would be scrapping TimesOfIndia RSS feeds to get news article text. This text is further passed to GloVe algorithm to create a brief summary of N sentences. \n",
    "\n",
    "Below is the basic data flow:\n",
    "1. Get RSS feed for a topic. RSS feed contains news headline, link and published-date. \n",
    "2. Fetch the link HTML which contains the actual news article. \n",
    "3. Using BeautifulSoup library, extract news text from it. \n",
    "4. Perform basic text pre-processing such as cleanup/normalization\n",
    "5. Generate sentence vectors using GloVe algorithm.\n",
    "6. Rank the sentences using pagerank algorithm. \n",
    "7. Take top N sentences which forms the summary of the news article.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for web and HTML\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the RSS feed\n",
    "\n",
    "Let's first read the RSS feed and will pass it to BeautifulSoup for HTML parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for category: topstories. \n",
      "RSS link: https://timesofindia.indiatimes.com/rssfeedstopstories.cms\n",
      "Fetching for: topstories\n",
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?><rss xmlns:atom=\"http://www.w3.org/2005/Atom\" version=\"2.0\"><channel><atom:link type=\"application/rss+xml\" rel=\"self\" href=\"https://timesofindia.indiatimes.com/rssfeedstopstories.cms\"/><title>Times of India</title><link>https://timesofindia.indiatimes.com</link><description>The Times of India: Breaking news, views, reviews, cricket from across India</description><language>en-gb</language><copyright>Copyright:(C) 2019 Bennett Coleman &amp; Co. Ltd, http://info.indiatimes.com/terms/tou.html</copyright><docs>http://timescontent.com/</docs><image><title>Times of India</title><link>https://timesofindia.indiatimes.com</link><url>https://timesofindia.indiatimes.com/photo.cms?msid=507610</url></image><item><title>Hyderabad encounter: Justice must never take form of revenge, says CJI</title><description>\"Justice is never ought to be instant. Justice must never ever take the form of revenge,\" said Chief Justice of India SA Bobde amid a raging debate on the justice delivery system in India over recent cases of rapes in Hyderabad and Unnao. \"There is a need in judiciary to invoke self-correcting measures,\" he said adding that publicising them is a matter of debate.</description><link>https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms</link><guid>https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms</guid><pubDate>Sat, 07 Dec 2019 10:56:42 GMT</pubDate></item><item><title>Rs 25L aid to Unnao victim\\'s family: Key points</title><description/><link>https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-key-developments/articleshow/72412517.cms</link><guid>https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-key-developments/articleshow/72412517.cms</guid><pubDate>Sat, 07 Dec 2019 06:50:08 GMT</pubDate></item><item><title>Unnao rape case will be fast-tracked: Yogi</title><description>\"All the accused people have been arrested. The case will be taken to a fast-track court, and punishment will be given,\" UP CM Yogi Adityanath said. The rape victim, airlifted to the Safdarjung Hospital in Delhi after she was set ablaze allegedly by five persons, died on Friday night. Yogi termed the death \"extremely sad\" and offered his condolences to the victim\\'s family.</description><link>https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-extremely-sad-case-will-be-fast-tracked-up-cm-yogi-adityanath/articleshow/72411151.cms</link><guid>https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-extremely-sad-case-will-be-fast-tracked-up-cm-yogi-adityanath/articleshow/72411151.cms</guid><pubDate>Sat, 07 Dec 2019 05:08:02 GMT</pubDate></item><item><title>Judicial process beyond reach of poor: Kovind</title><description>President Ram Nath Kovind on Saturday expressed concern over access to justice, saying the judicial process has gone beyond the reach of the common man. \"The judicial process has become expensive, even beyond the reach of common man due to many reasons, especially in the high court and the Supreme Court where it has become impossible for common litigants,\" Kovind said.</description><link>https://timesofindia.indiatimes.com/india/judicial-process-beyond-reach-of-poor-president-ram-nath-kovind/articleshow/72415797.cms</link><guid>https://timesofindia.indiatimes.com/india/judicial-process-beyond-reach-of-poor-president-ram-nath-kovind/articleshow/72415797.cms</guid><pubDate>Sat, 07 Dec 2019 11:48:07 GMT</pubDate></item><item><title>58.8% voting in Jharkhand till 3pm amid violence</title><description>Polling in 18 seats ended at 3pm, while voters in Jamshedpur (East) \\xe2\\x80\\x94 where chief minister Raghubar Das is in fray \\xe2\\x80\\x94 and Jamshedpur (West) constituencies can exercise their franchise till 5pm, an Election Commission (EC) release said. The voting commenced at 7am amid tight security arrangements.</description><link>https://timesofindia.indiatimes.com/india/58-8-voting-in-jharkhand-till-3-pm-amid-violence-1-killed/articleshow/72415392.cms</link><guid>https://timesofindia.indiatimes.com/india/58-8-voting-in-jharkhand-till-3-pm-amid-violence-1-killed/articleshow/72415392.cms</guid><pubDate>Sat, 07 Dec 2019 11:00:51 GMT</pubDate></item></channel></rss>'\n"
     ]
    }
   ],
   "source": [
    "# create a dict of various rss feed link and their categories. Will iterate them one by one.\n",
    "# Have enabled only one feed to create a pipeline.\n",
    "timesofindia = {'topstories':'https://timesofindia.indiatimes.com/rssfeedstopstories.cms',\n",
    "                #'mostrecentstories':'https://timesofindia.indiatimes.com/rssfeeds/1221656.cms',\n",
    "                #'world':'http://timesofindia.indiatimes.com/rssfeeds/296589292.cms'\n",
    "               }\n",
    "for category, rsslink in timesofindia.items():\n",
    "    print('Processing for category: {0}. \\nRSS link: {1}'.format(category,rsslink))\n",
    "    \n",
    "    # get the webpage URL and read the html\n",
    "    print('Fetching for:',category)\n",
    "    rssdata = requests.get(rsslink)\n",
    "    print(rssdata.content)\n",
    "#     soup = BeautifulSoup(data.content)\n",
    "#     print('-----------------------')\n",
    "#     print(soup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted HTML above looks raw and unformatted. Will pass it to BeautifulSoup library for parsing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<html>\n",
      " <body>\n",
      "  <rss version=\"2.0\" xmlns:atom=\"http://www.w3.org/2005/Atom\">\n",
      "   <channel>\n",
      "    <atom:link href=\"https://timesofindia.indiatimes.com/rssfeedstopstories.cms\" rel=\"self\" type=\"application/rss+xml\">\n",
      "    </atom:link>\n",
      "    <title>\n",
      "     Times of India\n",
      "    </title>\n",
      "    <link/>\n",
      "    https://timesofindia.indiatimes.com\n",
      "    <description>\n",
      "     The Times of India: Breaking news, views, reviews, cricket from across India\n",
      "    </description>\n",
      "    <language>\n",
      "     en-gb\n",
      "    </language>\n",
      "    <copyright>\n",
      "     Copyright:(C) 2019 Bennett Coleman &amp; Co. Ltd, http://info.indiatimes.com/terms/tou.html\n",
      "    </copyright>\n",
      "    <docs>\n",
      "     http://timescontent.com/\n",
      "    </docs>\n",
      "    <image>\n",
      "     <title>\n",
      "      Times of India\n",
      "     </title>\n",
      "     <link/>\n",
      "     https://timesofindia.indiatimes.com\n",
      "     <url>\n",
      "      https://timesofindia.indiatimes.com/photo.cms?msid=507610\n",
      "     </url>\n",
      "    </image>\n",
      "    <item>\n",
      "     <title>\n",
      "      Hyderabad encounter: Justice must never take form of revenge, says CJI\n",
      "     </title>\n",
      "     <description>\n",
      "      \"Justice is never ought to be instant. Justice must never ever take the form of revenge,\" said Chief Justice of India SA Bobde amid a raging debate on the justice delivery system in India over recent cases of rapes in Hyderabad and Unnao. \"There is a need in judiciary to invoke self-correcting measures,\" he said adding that publicising them is a matter of debate.\n",
      "     </description>\n",
      "     <link/>\n",
      "     https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms\n",
      "     <guid>\n",
      "      https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms\n",
      "     </guid>\n",
      "     <pubdate>\n",
      "      Sat, 07 Dec 2019 10:56:42 GMT\n",
      "     </pubdate>\n",
      "    </item>\n",
      "    <item>\n",
      "     <title>\n",
      "      Rs 25L aid to Unnao victim's family: Key points\n",
      "     </title>\n",
      "     <description>\n",
      "     </description>\n",
      "     <link/>\n",
      "     https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-key-developments/articleshow/72412517.cms\n",
      "     <guid>\n",
      "      https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-key-developments/articleshow/72412517.cms\n",
      "     </guid>\n",
      "     <pubdate>\n",
      "      Sat, 07 Dec 2019 06:50:08 GMT\n",
      "     </pubdate>\n",
      "    </item>\n",
      "    <item>\n",
      "     <title>\n",
      "      Unnao rape case will be fast-tracked: Yogi\n",
      "     </title>\n",
      "     <description>\n",
      "      \"All the accused people have been arrested. The case will be taken to a fast-track court, and punishment will be given,\" UP CM Yogi Adityanath said. The rape victim, airlifted to the Safdarjung Hospital in Delhi after she was set ablaze allegedly by five persons, died on Friday night. Yogi termed the death \"extremely sad\" and offered his condolences to the victim's family.\n",
      "     </description>\n",
      "     <link/>\n",
      "     https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-extremely-sad-case-will-be-fast-tracked-up-cm-yogi-adityanath/articleshow/72411151.cms\n",
      "     <guid>\n",
      "      https://timesofindia.indiatimes.com/india/unnao-rape-victims-death-extremely-sad-case-will-be-fast-tracked-up-cm-yogi-adityanath/articleshow/72411151.cms\n",
      "     </guid>\n",
      "     <pubdate>\n",
      "      Sat, 07 Dec 2019 05:08:02 GMT\n",
      "     </pubdate>\n",
      "    </item>\n",
      "    <item>\n",
      "     <title>\n",
      "      Judicial process beyond reach of poor: Kovind\n",
      "     </title>\n",
      "     <description>\n",
      "      President Ram Nath Kovind on Saturday expressed concern over access to justice, saying the judicial process has gone beyond the reach of the common man. \"The judicial process has become expensive, even beyond the reach of common man due to many reasons, especially in the high court and the Supreme Court where it has become impossible for common litigants,\" Kovind said.\n",
      "     </description>\n",
      "     <link/>\n",
      "     https://timesofindia.indiatimes.com/india/judicial-process-beyond-reach-of-poor-president-ram-nath-kovind/articleshow/72415797.cms\n",
      "     <guid>\n",
      "      https://timesofindia.indiatimes.com/india/judicial-process-beyond-reach-of-poor-president-ram-nath-kovind/articleshow/72415797.cms\n",
      "     </guid>\n",
      "     <pubdate>\n",
      "      Sat, 07 Dec 2019 11:48:07 GMT\n",
      "     </pubdate>\n",
      "    </item>\n",
      "    <item>\n",
      "     <title>\n",
      "      58.8% voting in Jharkhand till 3pm amid violence\n",
      "     </title>\n",
      "     <description>\n",
      "      Polling in 18 seats ended at 3pm, while voters in Jamshedpur (East) — where chief minister Raghubar Das is in fray — and Jamshedpur (West) constituencies can exercise their franchise till 5pm, an Election Commission (EC) release said. The voting commenced at 7am amid tight security arrangements.\n",
      "     </description>\n",
      "     <link/>\n",
      "     https://timesofindia.indiatimes.com/india/58-8-voting-in-jharkhand-till-3-pm-amid-violence-1-killed/articleshow/72415392.cms\n",
      "     <guid>\n",
      "      https://timesofindia.indiatimes.com/india/58-8-voting-in-jharkhand-till-3-pm-amid-violence-1-killed/articleshow/72415392.cms\n",
      "     </guid>\n",
      "     <pubdate>\n",
      "      Sat, 07 Dec 2019 11:00:51 GMT\n",
      "     </pubdate>\n",
      "    </item>\n",
      "   </channel>\n",
      "  </rss>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# pass rssdata html to BeautifulSoup for parsing\n",
    "soup = BeautifulSoup(rssdata.content)\n",
    "# prettify() will give the visual representation of the parse tree created from the raw HTML content.\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, you should go through the HTML content of the webpage which we printed above using soup.prettify() method and try to find a pattern or a way to navigate to get the news headline, link and pubDate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total news items found: 5\n",
      "Processing news-item #: 0\n",
      "<item><title>Hyderabad encounter: Justice must never take form of revenge, says CJI</title><description>\"Justice is never ought to be instant. Justice must never ever take the form of revenge,\" said Chief Justice of India SA Bobde amid a raging debate on the justice delivery system in India over recent cases of rapes in Hyderabad and Unnao. \"There is a need in judiciary to invoke self-correcting measures,\" he said adding that publicising them is a matter of debate.</description><link/>https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms<guid>https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms</guid><pubdate>Sat, 07 Dec 2019 10:56:42 GMT</pubdate></item>\n",
      "-------------------------\n",
      "TITLE: Hyderabad encounter: Justice must never take form of revenge, says CJI\n",
      "LINK: https://timesofindia.indiatimes.com/india/hyderabad-encounter-justice-must-never-take-form-of-revenge-says-cji-bobde/articleshow/72415223.cms\n",
      "PUBDATE: Sat, 07 Dec 2019 10:56:42 GMT\n"
     ]
    }
   ],
   "source": [
    "# get all news items. It has title, description, link, guid, pubdate for each news items. \n",
    "# Lets call this items and we will iterate thru it\n",
    "allitems = soup.find_all('item')\n",
    "print('Total news items found:',len(allitems))\n",
    "\n",
    "# print one news item/healine to check\n",
    "#for item in range(len(allitems)):\n",
    "for item in range(1):\n",
    "    print('Processing news-item #:',item)\n",
    "    print(allitems[item])\n",
    "    print('-------------------------')\n",
    "    title = allitems[item].title.text\n",
    "    link = allitems[item].guid.text\n",
    "    pubdate = allitems[item].pubdate.text\n",
    "    print('TITLE:',title)\n",
    "    print('LINK:',link)\n",
    "    print('PUBDATE:',pubdate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News Title, link, and publish-date looks expected. Creating a basic function to fetch news text from link. Using BeautifulSoup, will extract news text present in between specific html tags. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch each news link to get news essay \n",
    "def fetch_news_text(link):\n",
    "    # read the html webpage and parse it\n",
    "    soup = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "    \n",
    "    # fetch the news article text box\n",
    "    # these are with element \n",
    "    # <div class=\"_3WlLe clearfix\">\n",
    "    text_box = soup.find_all('div', attrs={'class':'_3WlLe clearfix'})\n",
    "    \n",
    "    # Need to remove embeded link of other article. \n",
    "    # these are with element \n",
    "    # <div class=\"_3RArp undefined\" data-type=\"embedgroup\">\n",
    "    remove_box = soup.find_all('div', attrs={'class':'_3RArp undefined','data-type':\"embedgroup\"})\n",
    "    \n",
    "    # PENDING: \n",
    "    # code to remove remove_box from text_box\n",
    "    \n",
    "    # extract text and combine\n",
    "    news_text = str(\". \".join(t.text.strip() for t in text_box))\n",
    "    \n",
    "    return news_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a loop to extract all news-stories in the RSS feed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Feed</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Link</th>\n",
       "      <th>NewsText</th>\n",
       "      <th>Pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Hyderabad encounter: Justice must never take f...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/hyde...</td>\n",
       "      <td>NEW DELHI: Amid a raging debate on the justice...</td>\n",
       "      <td>Sat, 07 Dec 2019 10:56:42 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Rs 25L aid to Unnao victim's family: Key points</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/unna...</td>\n",
       "      <td>NEW DELHI: The   rape victim from Uttar Prades...</td>\n",
       "      <td>Sat, 07 Dec 2019 06:50:08 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Unnao rape case will be fast-tracked: Yogi</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/unna...</td>\n",
       "      <td>LUCKNOW: Uttar Pradesh chief minister Yogi Adi...</td>\n",
       "      <td>Sat, 07 Dec 2019 05:08:02 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Judicial process beyond reach of poor: Kovind</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/judi...</td>\n",
       "      <td>JODHPUR: President Ram Nath Kovind here on Sat...</td>\n",
       "      <td>Sat, 07 Dec 2019 11:48:07 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>58.8% voting in Jharkhand till 3pm amid violence</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/58-8...</td>\n",
       "      <td>RANCHI: One person was killed as security pers...</td>\n",
       "      <td>Sat, 07 Dec 2019 11:00:51 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category          Feed  \\\n",
       "0  topstories  timesofindia   \n",
       "1  topstories  timesofindia   \n",
       "2  topstories  timesofindia   \n",
       "3  topstories  timesofindia   \n",
       "4  topstories  timesofindia   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Hyderabad encounter: Justice must never take f...   \n",
       "1    Rs 25L aid to Unnao victim's family: Key points   \n",
       "2         Unnao rape case will be fast-tracked: Yogi   \n",
       "3      Judicial process beyond reach of poor: Kovind   \n",
       "4   58.8% voting in Jharkhand till 3pm amid violence   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://timesofindia.indiatimes.com/india/hyde...   \n",
       "1  https://timesofindia.indiatimes.com/india/unna...   \n",
       "2  https://timesofindia.indiatimes.com/india/unna...   \n",
       "3  https://timesofindia.indiatimes.com/india/judi...   \n",
       "4  https://timesofindia.indiatimes.com/india/58-8...   \n",
       "\n",
       "                                            NewsText  \\\n",
       "0  NEW DELHI: Amid a raging debate on the justice...   \n",
       "1  NEW DELHI: The   rape victim from Uttar Prades...   \n",
       "2  LUCKNOW: Uttar Pradesh chief minister Yogi Adi...   \n",
       "3  JODHPUR: President Ram Nath Kovind here on Sat...   \n",
       "4  RANCHI: One person was killed as security pers...   \n",
       "\n",
       "                         Pubdate  \n",
       "0  Sat, 07 Dec 2019 10:56:42 GMT  \n",
       "1  Sat, 07 Dec 2019 06:50:08 GMT  \n",
       "2  Sat, 07 Dec 2019 05:08:02 GMT  \n",
       "3  Sat, 07 Dec 2019 11:48:07 GMT  \n",
       "4  Sat, 07 Dec 2019 11:00:51 GMT  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles = [{'Feed':'timesofindia',\n",
    "                  'Category':category, \n",
    "                  'Headline':allitems[item].title.text, \n",
    "                  'Link':allitems[item].guid.text, \n",
    "                  'Pubdate':allitems[item].pubdate.text,\n",
    "                  'NewsText': fetch_news_text(allitems[item].guid.text)} \n",
    "                     for item in range(5)]\n",
    "\n",
    "news_articles = pd.DataFrame(news_articles)\n",
    "news_articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pre-processing (cleanup/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries for text pre-processing\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from contractions import CONTRACTION_MAP # from contractions.py\n",
    "nlp = spacy.load('en',parse=True,tag=True, entity=True) # required for lemmatization\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing HTML tags\n",
    "\n",
    "Often, unstructured text contains a lot of noise, especially if you use techniques like web or screen scraping. HTML tags are typically one of these components which don’t add much value towards understanding and analyzing text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First sentence of news article. And another one.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing HTML tags\n",
    "def strip_html_tags(text):\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "strip_html_tags('<html><h2>First sentence of news article. And another one.</h2></html>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing accented characters\n",
    "\n",
    "Usually in any text corpus, you might be dealing with accented characters/letters, especially if you only want to analyze the English language. Hence, we need to make sure that these characters are converted and standardized into ASCII characters. A simple example — converting é to e.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing accented characters\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding Contractions\n",
    "Contractions are shortened version of words or syllables. They often exist in either written or spoken forms in the English language. These shortened versions or contractions of words are created by removing specific letters and sounds. In case of English contractions, they are often created by removing one of the vowels from the word. Examples would be, do not to don’t and I would to I’d. Converting each contraction to its expanded, original form helps with text standardization\n",
    "\n",
    "We leverage a standard set of contractions available in the contractions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all contractions expanded I would think.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all contractions expanded I'd think.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Special Characters and numbers\n",
    "\n",
    "Special characters and symbols are usually non-alphanumeric characters or even occasionally numeric characters (depending on the problem), which add to the extra noise in unstructured text. Usually, simple regular expressions (regexes) can be used to remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not sure if this was fun! What do you think of it.? !'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# added .,?:;'\" chars to retain\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9!.,?:;\\'\\\"\\s]' if not remove_digits else r'[^a-zA-z!.,?:;\\'\\\"\\s]'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "remove_special_characters(\"Not sure if this was fun! What do you think of it.? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming & Lemmatization\n",
    "\n",
    "Get base word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My car keep honking; my friend' honk yesterday.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"My car keeps honking; my friend's honked yesterday.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My car keep honking ; my friend 's honk yesterday .\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My car keeps honking; my friend's honked yesterday.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stopwords\n",
    "Words which have little or no significance, especially when constructing meaningful features from text, are known as stopwords or stop words. These are usually words that end up having the maximum frequency if you do a simple term or word frequency in a corpus. Typically, these can be articles, conjunctions, prepositions and so on. Some examples of stopwords are a, an, the, and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer not'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together to make a text normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the normalizer function by passing one new's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new delhi : amid rage debate justice delivery system india recent incident rape hyderabad unnao , chief justice india sa bobde saturday say criminal justice system must reconsider position attitude warn justice never take form revenge . chief justice remark come day four accuse brutal rape murder case year old woman veterinarian hyderabad allegedly kill exchange fire police . \" recent event country spark old debate new vigour , no doubt criminal justice system must reconsider position attitude towards time take dispose criminal matter , \" say . however , chief justice caution justice must never ought instant . \" justice never ought instant . justice must never ever take form revenge . believe justice lose character become revenge . need judiciary invoke self correct measure whether not publicise matter debate , \" say . say need devise method not speed litigation prevent altogether . \" law provide pre litigation mediation , \" say , add need consider compulsory pre litigation mediation . surprisingly , no course available confer degree diploma mediation , say . encounter killing four accuse gang rape murder hyderabad veterinarian trigger tsunami reaction across spectrum range appreciation condemnation . question \" encounter \" , many hail cop deliver \" justice \" . meanwhile , unnao rape victim , set ablaze accuse , die hospital delhi yesterday . incident spark nationwide outrage , several people demand speedy justice .']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test normalize cleanup on one article\n",
    "normalize_corpus([news_articles['NewsText'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector representation of sentence\n",
    "\n",
    "#### GloVe word embeddings\n",
    "We will be using the pre-trained Wikipedia 2014 + Gigaword 5 GloVe vectors available here. Heads up – the size of these word embeddings is 822 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract word vectors\n",
    "\n",
    "# define dict to hold a word and its vector\n",
    "word_embeddings = {}\n",
    "# read the file\n",
    "f = open('.\\\\GloVe\\\\glove.6B\\\\glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "len(word_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 400K word embedding. Now, let’s create vectors for our sentences. We will first fetch vectors (each of size 100 elements) for the constituent words in a sentence and then take mean/average of those vectors to arrive at a consolidated vector for the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will follow below steps pipeline\n",
    "1. create sentence from news article\n",
    "2. clean each sentences\n",
    "3. create vector for each sentences\n",
    "4. create simillarity-matrix\n",
    "5. Apply page-rank on simillarity-matrix\n",
    "6. get top N sentences based on page-rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentence: 15\n",
      "Total cleaned sentence: 15\n",
      "Total vectors created: 15\n"
     ]
    }
   ],
   "source": [
    "# lets take one news-article to create pipeline. We will generalize it for complete corpus\n",
    "# news_articles['CleanText'][2]\n",
    "\n",
    "# 1. create sentences for each news-article\n",
    "sentences = []\n",
    "\n",
    "for s in normalize_corpus([news_articles['NewsText'][0]]):\n",
    "#for s in [news_articles['NewsText'][2]]:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "\n",
    "# flatten the list\n",
    "sentences = [y for x in sentences for y in x]\n",
    "print('Total number of sentence: {0}'.format(format(len(sentences))))\n",
    "\n",
    "# 2. clean each sentences\n",
    "clean_sentences = normalize_corpus(sentences)\n",
    "print('Total cleaned sentence:',len(clean_sentences))\n",
    "\n",
    "# 3. create vector for each sentences\n",
    "# list to hold vector \n",
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)\n",
    "\n",
    "print('Total vectors created:',len(sentence_vectors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Matrix Preparation\n",
    "The next step is to find similarities between the sentences, and we will use the cosine similarity approach for this challenge. Let’s create an empty similarity matrix for this task and populate it with cosine similarities of the sentences.\n",
    "\n",
    "Let’s first define a zero matrix of dimensions (n * n).  We will initialize this matrix with cosine similarity scores of the sentences. Here, n is the number of sentences.\n",
    "\n",
    "We will use Cosine Similarity to compute the similarity between a pair of sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. create simillarity-matrix\n",
    "\n",
    "# similarity matrix\n",
    "# define matrix with all zero values\n",
    "# will populate it with cosine_similarity values \n",
    "# for each sentences compared to other\n",
    "\n",
    "sim_mat = np.zeros([len(sentences),len(sentences)])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100),\n",
    "                                              sentence_vectors[j].reshape(1,100))[0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PageRank Algorithm\n",
    "\n",
    "Before proceeding further, let’s convert the similarity matrix sim_mat into a graph. The nodes of this graph will represent the sentences and the edges will represent the similarity scores between the sentences. On this graph, we will apply the PageRank algorithm to arrive at the sentence rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.06877575530748713,\n",
       " 1: 0.06620696025988485,\n",
       " 2: 0.06961142749476128,\n",
       " 3: 0.06836042068386161,\n",
       " 4: 0.06587982908448074,\n",
       " 5: 0.06845233661633444,\n",
       " 6: 0.06697288393169526,\n",
       " 7: 0.06734312758532424,\n",
       " 8: 0.06658546976256263,\n",
       " 9: 0.06675300416936665,\n",
       " 10: 0.06527808631852403,\n",
       " 11: 0.06309025837987235,\n",
       " 12: 0.06610562619331287,\n",
       " 13: 0.06400456067973156,\n",
       " 14: 0.06658025353280025}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL STEP:  Summary Extraction\n",
    "\n",
    "Finally, it’s time to extract the top N sentences based on their rankings for summary generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent event country spark old debate new vigour , no doubt criminal justice system must reconsider position attitude towards time take dispose criminal matter , \" say .\n",
      "new delhi : amid rage debate justice delivery system india recent incident rape hyderabad unnao , chief justice india sa bobde saturday say criminal justice system must reconsider position attitude warn justice never take form revenge .\n",
      "justice must never ever take form revenge .\n",
      "however , chief justice caution justice must never ought instant . \"\n",
      "need judiciary invoke self correct measure whether not publicise matter debate , \" say .\n"
     ]
    }
   ],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "# Extract top 10 sentences as the summary\n",
    "for i in range(5):\n",
    "    print(ranked_sentences[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing it all together — Building a News Briefer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for web and HTML\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for text pre-processing\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from contractions import CONTRACTION_MAP # from contractions.py\n",
    "nlp = spacy.load('en',parse=True,tag=True, entity=True) # required for lemmatization\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch each news link to get news essay \n",
    "def fetch_news_text(link):\n",
    "    # read the html webpage and parse it\n",
    "    soup = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "    \n",
    "    # fetch the news article text box\n",
    "    # these are with element \n",
    "    # <div class=\"_3WlLe clearfix\">\n",
    "    text_box = soup.find_all('div', attrs={'class':'_3WlLe clearfix'})\n",
    "    \n",
    "    # Need to remove embeded link of other article. \n",
    "    # these are with element \n",
    "    # <div class=\"_3RArp undefined\" data-type=\"embedgroup\">\n",
    "    remove_box = soup.find_all('div', attrs={'class':'_3RArp undefined','data-type':\"embedgroup\"})\n",
    "    \n",
    "    # PENDING: \n",
    "    # code to remove remove_box from text_box\n",
    "    \n",
    "    # extract text and combine\n",
    "    news_text = str(\". \".join(t.text.strip() for t in text_box))\n",
    "    \n",
    "    return news_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function for normalizer\n",
    "# Removing HTML tags\n",
    "def strip_html_tags(text):\n",
    "    #soup = BeautifulSoup(text,'html.parser')\n",
    "    soup = BeautifulSoup(text)\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "\n",
    "# removing accented characters\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "# remove special characters\n",
    "# added .,?:;'\" chars to retain\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9!.,?:;\\'\\\"\\s]' if not remove_digits else r'[^a-zA-z!.,?:;\\'\\\"\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# stemmer\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "# lemmatization\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "# remove stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean and normalize text corpus\n",
    "#def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "def normalize_corpus(doc, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    #normalized_corpus = []\n",
    "    #normalized_doc = ''\n",
    "    # normalize each document in the corpus\n",
    "    #for doc in corpus:\n",
    "    # strip HTML\n",
    "    if html_stripping:\n",
    "        doc = strip_html_tags(doc)\n",
    "    # remove accented characters\n",
    "    if accented_char_removal:\n",
    "        doc = remove_accented_chars(doc)\n",
    "    # expand contractions    \n",
    "    if contraction_expansion:\n",
    "        doc = expand_contractions(doc)\n",
    "    # lowercase the text    \n",
    "    if text_lower_case:\n",
    "        doc = doc.lower()\n",
    "    # remove extra newlines\n",
    "    doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "    # lemmatize text\n",
    "    if text_lemmatization:\n",
    "        doc = lemmatize_text(doc)\n",
    "    # remove special characters and\\or digits    \n",
    "    if special_char_removal:\n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "    # remove extra whitespace\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    # remove stopwords\n",
    "    if stopword_removal:\n",
    "        doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "\n",
    "    #normalized_corpus.append(doc)\n",
    "\n",
    "    #return normalized_corpus\n",
    "    return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract word vectors\n",
    "\n",
    "# define dict to hold a word and its vector\n",
    "word_embeddings = {}\n",
    "# read the file\n",
    "f = open('.\\\\GloVe\\\\glove.6B\\\\glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to summarize a corpus\n",
    "def summarize(corpus,     # text corpus to summarize\n",
    "              summ_cnt=5  # count of summary lines required\n",
    "             ):\n",
    "    \n",
    "    # create sentences for each news-article\n",
    "    # list to hold sentences\n",
    "    sentences = []\n",
    "    sentences.append(sent_tokenize(corpus))\n",
    "    # flatten the list\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    #print('Total number of sentence: {0}'.format(format(len(sentences))))\n",
    "\n",
    "    # skipping cleanup & normalize step because we already did in previous step\n",
    "    # 2. clean & normalize each sentences\n",
    "    # clean_sentences = normalize_corpus(sentences)\n",
    "    # print('Total cleaned sentence:',len(clean_sentences))\n",
    "\n",
    "    # 3. create vector for each sentences\n",
    "    # list to hold vector \n",
    "    sentence_vectors = []\n",
    "    #for i in clean_sentences:\n",
    "    for i in sentences:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((100,))\n",
    "        sentence_vectors.append(v)\n",
    "    #print('Total vectors created:',len(sentence_vectors))\n",
    "\n",
    "    # 4. create simillarity-matrix\n",
    "    # similarity matrix and populate with cosine comparision values\n",
    "    sim_mat = np.zeros([len(sentences),len(sentences)])\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100),\n",
    "                                                  sentence_vectors[j].reshape(1,100))[0,0]\n",
    "\n",
    "    # Apply pagerank algorithm\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "\n",
    "    # Extract top 10 sentences as the summary\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "    summary = ''\n",
    "    summ_cnt = summ_cnt if summ_cnt < len(sentences) else len(sentences)\n",
    "    for i in range(summ_cnt):\n",
    "        summary = summary + ranked_sentences[i][1]\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed: timesofindia\n",
      "- Fetching topstories.\n",
      " - Found 5 items\n",
      "  - Processing item # 0\n",
      "  - Processing item # 1\n",
      "  - Processing item # 2\n",
      "  - Processing item # 3\n",
      "  - Processing item # 4\n",
      "- Fetching mostrecentstories.\n",
      " - Found 20 items\n",
      "  - Processing item # 0\n",
      "  - Processing item # 1\n",
      "  - Processing item # 2\n",
      "  - Processing item # 3\n",
      "  - Processing item # 4\n",
      "  - Processing item # 5\n",
      "  - Processing item # 6\n",
      "  - Processing item # 7\n",
      "  - Processing item # 8\n",
      "  - Processing item # 9\n",
      "  - Processing item # 10\n",
      "  - Processing item # 11\n",
      "  - Processing item # 12\n",
      "  - Processing item # 13\n",
      "  - Processing item # 14\n",
      "  - Processing item # 15\n",
      "  - Processing item # 16\n",
      "  - Processing item # 17\n",
      "  - Processing item # 18\n",
      "  - Processing item # 19\n",
      "- Fetching world.\n",
      " - Found 20 items\n",
      "  - Processing item # 0\n",
      "  - Processing item # 1\n",
      "  - Processing item # 2\n",
      "  - Processing item # 3\n",
      "  - Processing item # 4\n",
      "  - Processing item # 5\n",
      "  - Processing item # 6\n",
      "  - Processing item # 7\n",
      "  - Processing item # 8\n",
      "  - Processing item # 9\n",
      "  - Processing item # 10\n",
      "  - Processing item # 11\n",
      "  - Processing item # 12\n",
      "  - Processing item # 13\n",
      "  - Processing item # 14\n",
      "  - Processing item # 15\n",
      "  - Processing item # 16\n",
      "  - Processing item # 17\n",
      "  - Processing item # 18\n",
      "  - Processing item # 19\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# create a dict of various rss feed link and their categories. Will iterate them one by one.\n",
    "timesofindia = {'topstories':'https://timesofindia.indiatimes.com/rssfeedstopstories.cms',\n",
    "                'mostrecentstories':'https://timesofindia.indiatimes.com/rssfeeds/1221656.cms',\n",
    "                'world':'http://timesofindia.indiatimes.com/rssfeeds/296589292.cms'\n",
    "               }\n",
    "\n",
    "# create list to hold all news article details\n",
    "news_articles = []\n",
    "\n",
    "feed_name = 'timesofindia'\n",
    "print('Feed:',feed_name)\n",
    "for category, rsslink in timesofindia.items():\n",
    "    # read HTML webpage from RSS URL\n",
    "    print('- Fetching {0}.'.format(category))\n",
    "    rssdata = requests.get(rsslink)\n",
    "    \n",
    "    # pass rssdata html to BeautifulSoup for parsing\n",
    "    soup = BeautifulSoup(rssdata.content)\n",
    "    \n",
    "    # extract all news items. It has title, description, link, guid, pubdate for each news items. \n",
    "    allitems = soup.find_all('item')\n",
    "    print(' - Found {0} items'.format(len(allitems)))\n",
    "    \n",
    "    for item in range(len(allitems)):\n",
    "        print('  - Processing item #',item)\n",
    "        headline = allitems[item].title.text\n",
    "        link = allitems[item].guid.text\n",
    "        pubdate = allitems[item].pubdate.text\n",
    "        newstext = fetch_news_text(link)\n",
    "        newstext_clean = normalize_corpus(newstext)\n",
    "        newstext_smry = summarize(newstext_clean)\n",
    "        \n",
    "        # combine all parts into one list and append to main list\n",
    "        this_item = [{'Feed':feed_name,\n",
    "                      'Category':category, \n",
    "                      'Headline':headline, \n",
    "                      'Link':link, \n",
    "                      'Pubdate':pubdate,\n",
    "                      'NewsText': newstext,\n",
    "                      'NewstextClean':newstext_clean,\n",
    "                      'NewstextSmry':newstext_smry,\n",
    "                     }]\n",
    "        news_articles.extend(this_item)\n",
    "\n",
    "# create final dataframe\n",
    "news_articles = pd.DataFrame(news_articles)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Feed</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Link</th>\n",
       "      <th>NewsText</th>\n",
       "      <th>NewstextClean</th>\n",
       "      <th>NewstextSmry</th>\n",
       "      <th>Pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>UP govt announces Rs 25L financial aid for Unn...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/unna...</td>\n",
       "      <td>NEW DELHI: The   rape victim from Uttar Prades...</td>\n",
       "      <td>new delhi : rape victim uttar pradesh unnao di...</td>\n",
       "      <td>no fear among criminal state , \" say meet vict...</td>\n",
       "      <td>Sat, 07 Dec 2019 06:50:08 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Justice must never take form of revenge, says CJI</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/hyde...</td>\n",
       "      <td>NEW DELHI: Amid a raging debate on the justice...</td>\n",
       "      <td>new delhi : amid rage debate justice delivery ...</td>\n",
       "      <td>recent event country spark old debate new vigo...</td>\n",
       "      <td>Sat, 07 Dec 2019 10:56:42 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Hyderabad encounter: NHRC team begins probe</td>\n",
       "      <td>https://timesofindia.indiatimes.com/city/hyder...</td>\n",
       "      <td>HYDERABAD: A seven-member NHRC team on Saturda...</td>\n",
       "      <td>hyderabad : seven member nhrc team saturday vi...</td>\n",
       "      <td>however , political leader prominent people sp...</td>\n",
       "      <td>Sat, 07 Dec 2019 13:47:42 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Unnao rape case will be fast-tracked: Yogi</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/unna...</td>\n",
       "      <td>LUCKNOW: Uttar Pradesh chief minister Yogi Adi...</td>\n",
       "      <td>lucknow : uttar pradesh chief minister yogi ad...</td>\n",
       "      <td>unnao rape victim dad want hyderabad like puni...</td>\n",
       "      <td>Sat, 07 Dec 2019 05:08:02 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topstories</td>\n",
       "      <td>timesofindia</td>\n",
       "      <td>Judicial process beyond reach of poor: Kovind</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/judi...</td>\n",
       "      <td>JODHPUR: President Ram Nath Kovind here on Sat...</td>\n",
       "      <td>jodhpur : president ram nath kovind saturday e...</td>\n",
       "      <td>keep mind gandhiji famous criterion , remember...</td>\n",
       "      <td>Sat, 07 Dec 2019 11:48:07 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category          Feed  \\\n",
       "0  topstories  timesofindia   \n",
       "1  topstories  timesofindia   \n",
       "2  topstories  timesofindia   \n",
       "3  topstories  timesofindia   \n",
       "4  topstories  timesofindia   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  UP govt announces Rs 25L financial aid for Unn...   \n",
       "1  Justice must never take form of revenge, says CJI   \n",
       "2        Hyderabad encounter: NHRC team begins probe   \n",
       "3         Unnao rape case will be fast-tracked: Yogi   \n",
       "4      Judicial process beyond reach of poor: Kovind   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://timesofindia.indiatimes.com/india/unna...   \n",
       "1  https://timesofindia.indiatimes.com/india/hyde...   \n",
       "2  https://timesofindia.indiatimes.com/city/hyder...   \n",
       "3  https://timesofindia.indiatimes.com/india/unna...   \n",
       "4  https://timesofindia.indiatimes.com/india/judi...   \n",
       "\n",
       "                                            NewsText  \\\n",
       "0  NEW DELHI: The   rape victim from Uttar Prades...   \n",
       "1  NEW DELHI: Amid a raging debate on the justice...   \n",
       "2  HYDERABAD: A seven-member NHRC team on Saturda...   \n",
       "3  LUCKNOW: Uttar Pradesh chief minister Yogi Adi...   \n",
       "4  JODHPUR: President Ram Nath Kovind here on Sat...   \n",
       "\n",
       "                                       NewstextClean  \\\n",
       "0  new delhi : rape victim uttar pradesh unnao di...   \n",
       "1  new delhi : amid rage debate justice delivery ...   \n",
       "2  hyderabad : seven member nhrc team saturday vi...   \n",
       "3  lucknow : uttar pradesh chief minister yogi ad...   \n",
       "4  jodhpur : president ram nath kovind saturday e...   \n",
       "\n",
       "                                        NewstextSmry  \\\n",
       "0  no fear among criminal state , \" say meet vict...   \n",
       "1  recent event country spark old debate new vigo...   \n",
       "2  however , political leader prominent people sp...   \n",
       "3  unnao rape victim dad want hyderabad like puni...   \n",
       "4  keep mind gandhiji famous criterion , remember...   \n",
       "\n",
       "                         Pubdate  \n",
       "0  Sat, 07 Dec 2019 06:50:08 GMT  \n",
       "1  Sat, 07 Dec 2019 10:56:42 GMT  \n",
       "2  Sat, 07 Dec 2019 13:47:42 GMT  \n",
       "3  Sat, 07 Dec 2019 05:08:02 GMT  \n",
       "4  Sat, 07 Dec 2019 11:48:07 GMT  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Feed', 'Headline', 'Link', 'NewsText', 'NewstextClean',\n",
       "       'NewstextSmry', 'Pubdate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mostrecentstories    20\n",
       "world                20\n",
       "topstories            5\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulation, you have build a news briefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
